{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second attempt at the python version of the centralised part of the microarray methylation analysis workflow (Quality control upto normalisation)\n",
    "Using python as a shell to string together the specialised r functions used in the Exeter workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the required modules/packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# stuff needed for some specific analysis - maybe not needed in this version of the code\n",
    "#from sklearn.decomposition import PCA \n",
    "#from scipy.stats import pearsonr\n",
    "#from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_path = \"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Federated_Differential_Methylation_Analysis\"\n",
    "data_path = \"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Data\"\n",
    "output_path = \"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\Practical work\\\\Federated_Differential_Methylation_Analysis\\\\Output\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use subprocess to read the data contained in the idat files into dataframe using the readEPIC function from the wateRmelon package in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an output file structure and loading in the idat files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input arguments of this script are: \n",
    "1. file_path to the folder containing the .idat files \n",
    "2. file_path to the phenotype information sheet (.txt) \n",
    "3. the directory where the output should be saved \n",
    "4. OPTIONAL the data identifier to be used in the creation of the output folders - this still needs to be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_with_option = subprocess.run([\"C:\\\\Program Files\\\\R\\\\R-4.1.2\\\\bin\\\\Rscript.exe\", '--vanilla', \"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Federated_Differential_Methylation_Analysis\\\\Loading_idats_code_saveOutput_python_shell.R\", \"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Data\\\\GSE66351_RAW\\\\idat\", \"E:\\Msc Systems Biology\\MSB5000_Master_Thesis\\Practical work\\Data\\GSE66351_RAW\\GSE66351_pheno.txt\", \"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\Practical work\\\\Federated_Differential_Methylation_Analysis\\\\Output\", \"GSE66351a\"], capture_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_with_option.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using subprocess to perform the complete preprocessing workflow upto the normalisation  \n",
    "This is the whole preprocessing run as one function in the r-script. The script takes 5 input arguments:  \n",
    "1. The file path of the folder containing the .idat files\n",
    "2. The phenotype information file\n",
    "3. The working directory where the output folder should be created\n",
    "4. The filepath to the illumina manifest file that contains the column \"CHR\" with the chromosome each probe is located on\n",
    "5. The identifier that should be included in the name of the output folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_preprocessing = subprocess.run([\"C:\\\\Program Files\\\\R\\\\R-4.1.2\\\\bin\\\\Rscript.exe\", '--vanilla', \"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Federated_Differential_Methylation_Analysis\\\\preprocessing_r_code_replication_shell_version_no_norm_edit.r\", \"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Data\\\\GSE66351_RAW\\\\idat\", \"E:\\Msc Systems Biology\\MSB5000_Master_Thesis\\Practical work\\Data\\GSE66351_RAW\\GSE66351_pheno.txt\", \"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\Practical work\\\\Federated_Differential_Methylation_Analysis\\\\Output\", \"E:\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Data\\\\GSE66351_RAW\\\\GSE66351\\\\GPL13534_HumanMethylation450_15017482_v.1.1.csv\", \"GSE66351\"], capture_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Bioconductor version 3.14 (BiocManager 1.30.16), R 4.1.2 (2021-11-01)\\r\\nInstallation paths not writeable, unable to update packages\\r\\n  path: C:/Program Files/R/R-4.1.2/library\\r\\n  packages:\\r\\n    class, cluster, foreign, MASS, Matrix, mgcv, nlme, nnet, rpart, spatial,\\r\\n    survival\\r\\nOld packages: \\'AnnotationHub\\', \\'beanplot\\', \\'BiocManager\\', \\'blob\\', \\'broom\\',\\r\\n  \\'checkmate\\', \\'cli\\', \\'clipr\\', \\'colorspace\\', \\'commonmark\\', \\'crayon\\', \\'dplyr\\',\\r\\n  \\'DT\\', \\'ensembldb\\', \\'evaluate\\', \\'fansi\\', \\'formatR\\', \\'GenomicFeatures\\', \\'glue\\',\\r\\n  \\'Gviz\\', \\'haven\\', \\'Hmisc\\', \\'jsonlite\\', \\'knitr\\', \\'limma\\', \\'locfit\\', \\'magrittr\\',\\r\\n  \\'matrixStats\\', \\'openssl\\', \\'plyr\\', \\'processx\\', \\'ps\\', \\'RColorBrewer\\', \\'Rcpp\\',\\r\\n  \\'RCurl\\', \\'readxl\\', \\'reshape\\', \\'rhdf5\\', \\'rlang\\', \\'rmarkdown\\', \\'RSQLite\\',\\r\\n  \\'S4Vectors\\', \\'sass\\', \\'scales\\', \\'tidyselect\\', \\'tinytex\\', \\'tzdb\\', \\'uuid\\',\\r\\n  \\'vctrs\\', \\'withr\\', \\'xfun\\', \\'XML\\', \\'yaml\\'\\r\\nWarning message:\\r\\npackage(s) not installed when version(s) same as current; use `force = TRUE` to\\r\\n  re-install: \\'wateRmelon\\' \\'methylumi\\' \\'ChAMP\\' \\r\\nLoading required package: Biobase\\r\\nLoading required package: BiocGenerics\\r\\n\\r\\nAttaching package: \\'BiocGenerics\\'\\r\\n\\r\\nThe following objects are masked from \\'package:stats\\':\\r\\n\\r\\n    IQR, mad, sd, var, xtabs\\r\\n\\r\\nThe following objects are masked from \\'package:base\\':\\r\\n\\r\\n    anyDuplicated, append, as.data.frame, basename, cbind, colnames,\\r\\n    dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep,\\r\\n    grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget,\\r\\n    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,\\r\\n    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,\\r\\n    union, unique, unsplit, which.max, which.min\\r\\n\\r\\nWelcome to Bioconductor\\r\\n\\r\\n    Vignettes contain introductory material; view with\\r\\n    \\'browseVignettes()\\'. To cite Bioconductor, see\\r\\n    \\'citation(\"Biobase\")\\', and for packages \\'citation(\"pkgname\")\\'.\\r\\n\\r\\nLoading required package: limma\\r\\n\\r\\nAttaching package: \\'limma\\'\\r\\n\\r\\nThe following object is masked from \\'package:BiocGenerics\\':\\r\\n\\r\\n    plotMA\\r\\n\\r\\nLoading required package: matrixStats\\r\\n\\r\\nAttaching package: \\'matrixStats\\'\\r\\n\\r\\nThe following objects are masked from \\'package:Biobase\\':\\r\\n\\r\\n    anyMissing, rowMedians\\r\\n\\r\\nLoading required package: methylumi\\r\\nLoading required package: scales\\r\\nLoading required package: reshape2\\r\\nLoading required package: ggplot2\\r\\nLoading required package: FDb.InfiniumMethylation.hg19\\r\\nLoading required package: GenomicFeatures\\r\\nLoading required package: S4Vectors\\r\\nLoading required package: stats4\\r\\n\\r\\nAttaching package: \\'S4Vectors\\'\\r\\n\\r\\nThe following objects are masked from \\'package:base\\':\\r\\n\\r\\n    expand.grid, I, unname\\r\\n\\r\\nLoading required package: IRanges\\r\\n\\r\\nAttaching package: \\'IRanges\\'\\r\\n\\r\\nThe following object is masked from \\'package:grDevices\\':\\r\\n\\r\\n    windows\\r\\n\\r\\nLoading required package: GenomeInfoDb\\r\\nLoading required package: GenomicRanges\\r\\nLoading required package: AnnotationDbi\\r\\nLoading required package: TxDb.Hsapiens.UCSC.hg19.knownGene\\r\\nLoading required package: org.Hs.eg.db\\r\\n\\r\\nLoading required package: minfi\\r\\nLoading required package: SummarizedExperiment\\r\\nLoading required package: MatrixGenerics\\r\\n\\r\\nAttaching package: \\'MatrixGenerics\\'\\r\\n\\r\\nThe following objects are masked from \\'package:matrixStats\\':\\r\\n\\r\\n    colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse,\\r\\n    colCounts, colCummaxs, colCummins, colCumprods, colCumsums,\\r\\n    colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs,\\r\\n    colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats,\\r\\n    colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds,\\r\\n    colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads,\\r\\n    colWeightedMeans, colWeightedMedians, colWeightedSds,\\r\\n    colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet,\\r\\n    rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods,\\r\\n    rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps,\\r\\n    rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins,\\r\\n    rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks,\\r\\n    rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars,\\r\\n    rowWeightedMads, rowWeightedMeans, rowWeightedMedians,\\r\\n    rowWeightedSds, rowWeightedVars\\r\\n\\r\\nThe following object is masked from \\'package:Biobase\\':\\r\\n\\r\\n    rowMedians\\r\\n\\r\\nLoading required package: Biostrings\\r\\nLoading required package: XVector\\r\\n\\r\\nAttaching package: \\'Biostrings\\'\\r\\n\\r\\nThe following object is masked from \\'package:base\\':\\r\\n\\r\\n    strsplit\\r\\n\\r\\nLoading required package: bumphunter\\r\\nLoading required package: foreach\\r\\nLoading required package: iterators\\r\\nLoading required package: parallel\\r\\nLoading required package: locfit\\r\\nlocfit 1.5-9.4 \\t 2020-03-24\\r\\nSetting options(\\'download.file.method.GEOquery\\'=\\'auto\\')\\nSetting options(\\'GEOquery.inmemory.gpl\\'=FALSE)\\nLoading required package: lumi\\nNo methods found in package \\'RSQLite\\' for request: \\'dbListFields\\' when loading \\'lumi\\'\\n\\nAttaching package: \\'lumi\\'\\n\\nThe following objects are masked from \\'package:methylumi\\':\\n\\n    estimateM, getHistory\\n\\nLoading required package: ROC\\nLoading required package: IlluminaHumanMethylation450kanno.ilmn12.hg19\\nLoading required package: illuminaio\\nLoading required package: ChAMPdata\\nLoading required package: DMRcate\\nLoading required package: Illumina450ProbeVariants.db\\nLoading required package: IlluminaHumanMethylationEPICmanifest\\nLoading required package: DT\\nLoading required package: RPMM\\nLoading required package: cluster\\n\\n>> Package version 2.21.1 loaded <<\\n       ___ _      _   __  __ ___ \\n      / __| |_   /_\\\\ |  \\\\/  | _ \\\\\\n     | (__| \\' \\\\ / _ \\\\| |\\\\/| |  _/\\n      \\\\___|_||_/_/ \\\\_\\\\_|  |_|_|  \\n      ------------------------------\\n    If you have any question or suggestion about ChAMP, please email to champ450k@gmail.com.\\n    Thank you for citating ChAMP:\\n\\n    Yuan Tian, Tiffany J Morris, Amy P Webster, Zhen Yang, Stephan Beck, Andrew Feber, Andrew E Teschendorff; ChAMP: updated methylation analysis pipeline for Illumina BeadChips, Bioinformatics, btx513, https://doi.org/10.1093/bioinformatics/btx513\\n     --------------------------\\n\\nThere were 11 warnings (use warnings() to see them)\\nReading in: GSM2808875_8918692108_R01C02_Grn.idat\\nReading in: GSM2808875_8918692108_R01C02_Red.idat\\nReading in: GSM2808876_8918692108_R01C01_Grn.idat\\nReading in: GSM2808876_8918692108_R01C01_Red.idat\\nReading in: GSM2808877_8918692108_R02C02_Grn.idat\\nReading in: GSM2808877_8918692108_R02C02_Red.idat\\nReading in: GSM2808878_8918692108_R02C01_Grn.idat\\nReading in: GSM2808878_8918692108_R02C01_Red.idat\\nReading in: GSM2808879_8918692108_R03C02_Grn.idat\\nReading in: GSM2808879_8918692108_R03C02_Red.idat\\nReading in: GSM2808880_8918692108_R03C01_Grn.idat\\nReading in: GSM2808880_8918692108_R03C01_Red.idat\\nReading in: GSM2808881_8918692108_R04C02_Grn.idat\\nReading in: GSM2808881_8918692108_R04C02_Red.idat\\nReading in: GSM2808882_8918692108_R04C01_Grn.idat\\nReading in: GSM2808882_8918692108_R04C01_Red.idat\\nReading in: GSM2808883_8918692108_R05C02_Grn.idat\\nReading in: GSM2808883_8918692108_R05C02_Red.idat\\nReading in: GSM2808884_8918692108_R05C01_Grn.idat\\nReading in: GSM2808884_8918692108_R05C01_Red.idat\\nReading in: GSM2808885_8918692108_R06C02_Grn.idat\\nReading in: GSM2808885_8918692108_R06C02_Red.idat\\nReading in: GSM2808886_8918692108_R06C01_Grn.idat\\nReading in: GSM2808886_8918692108_R06C01_Red.idat\\nReading in: GSM2808887_8918692120_R04C02_Grn.idat\\nReading in: GSM2808887_8918692120_R04C02_Red.idat\\nReading in: GSM2808888_8918692120_R04C01_Grn.idat\\nReading in: GSM2808888_8918692120_R04C01_Red.idat\\nReading in: GSM2808889_8918692120_R05C02_Grn.idat\\nReading in: GSM2808889_8918692120_R05C02_Red.idat\\nReading in: GSM2808890_8918692120_R05C01_Grn.idat\\nReading in: GSM2808890_8918692120_R05C01_Red.idat\\nReading in: GSM2808891_8918692120_R06C02_Grn.idat\\nReading in: GSM2808891_8918692120_R06C02_Red.idat\\nReading in: GSM2808892_8918692120_R06C01_Grn.idat\\nReading in: GSM2808892_8918692120_R06C01_Red.idat\\nReading in: GSM2808893_8221932039_R04C01_Grn.idat\\nReading in: GSM2808893_8221932039_R04C01_Red.idat\\nReading in: GSM2808894_8221932039_R03C01_Grn.idat\\nReading in: GSM2808894_8221932039_R03C01_Red.idat\\n0 HumanMethylationEpic samples found\\n20 HumanMethylation450 samples found\\n0 HumanMethylation27 samples found\\nAttempting to extract protocolData() from list...\\nDetermining chip type from IDAT protocolData...\\nThere were 40 warnings (use warnings() to see them)\\n'\n",
      "b'[[1]]\\n[[1]]$value\\nfunction (betas, sex, npcs = 20, thres = 0.5, makePlot = TRUE) \\n{\\n    if (npcs > ncol(betas)) {\\n        npcs <- ncol(betas)\\n        print(paste(\"As only\", ncol(betas), \"samples, can look look at that number of PCs\", \\n            sep = \" \"))\\n    }\\n    betas.com <- betas[complete.cases(betas), ]\\n    pca <- prcomp(betas.com)\\n    pca.cor <- rep(NA, npcs)\\n    for (i in 1:npcs) {\\n        pca.cor[i] <- cor(pca$rotation[, i], as.numeric(as.factor(sex)), \\n            use = \"complete\")\\n    }\\n    top <- order(abs(pca.cor), decreasing = TRUE)[1]\\n    second <- order(abs(pca.cor), decreasing = TRUE)[2]\\n    print(paste(\"Top correlated principal components with sex:\", \\n        top, \",\", second))\\n    if (makePlot) {\\n        plot(pca$rotation[, top], pca$rotation[, second], pch = 16, \\n            col = c(\"magenta\", \"blue\")[as.factor(sex)], xlab = paste(\"PC\", \\n                top), ylab = paste(\"PC\", second))\\n        legend(\"topright\", levels(as.factor(sex)), pch = 16, \\n            col = c(\"magenta\", \"blue\"))\\n    }\\n    predSex_num <- kmeans(pca$rotation[, which(abs(pca.cor) > \\n        thres)], 2)$cluster\\n    predSex <- rep(NA, length(sex))\\n    options.sex <- levels(as.factor(sex))\\n    maxSample <- which.max(pca$rotation[, top])\\n    samplePredSex <- predSex_num[maxSample]\\n    sampleRepSex <- sex[maxSample]\\n    sampleOptionSex <- which(options.sex == sampleRepSex)\\n    predSex[which(predSex_num == samplePredSex)] <- options.sex[sampleOptionSex]\\n    predSex[which(predSex_num != samplePredSex)] <- options.sex[-sampleOptionSex]\\n    return(predSex)\\n}\\n\\n[[1]]$visible\\n[1] FALSE\\n\\n\\n[[2]]\\n[[2]]$value\\nfunction (betas, population = \"EUR\", maf = 0.05) \\n{\\n    snpProbes <- read.table(url(\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4909830/bin/mmc1.txt\"), \\n        header = TRUE)\\n    if (sum(startsWith(rownames(betas), \"cg\"))/nrow(betas) == \\n        0) {\\n        stop(\"Rownames are not cg identifiers\")\\n    }\\n    if (!population %in% c(\"Unknown\", \"AFR\", \"AMR\", \"EUR\", \"SAS\", \\n        \"EAS\")) {\\n        stop(\"Specified population not available list\")\\n    }\\n    else {\\n        if (population == \"Unknown\") {\\n            snpProbes <- snpProbes[which(snpProbes$AF >= maf & \\n                snpProbes$AF <= (1 - maf)), ]\\n        }\\n        else {\\n            snpProbes <- snpProbes[which(snpProbes[, paste(population, \\n                \"AF\", sep = \"_\")] >= maf & snpProbes[, paste(population, \\n                \"AF\", sep = \"_\")] <= (1 - maf)), ]\\n        }\\n        betas <- betas[!rownames(betas) %in% unique(snpProbes$IlmnID), \\n            ]\\n        return(betas)\\n    }\\n}\\n\\n[[2]]$visible\\n[1] FALSE\\n\\n\\n[[3]]\\n[[3]]$value\\nfunction (betas, sex, npcs = 20) \\n{\\n    betas.com <- betas[complete.cases(betas), ]\\n    pca <- prcomp(betas.com)\\n    pca.cor <- rep(NA, npcs)\\n    for (i in 1:npcs) {\\n        pca.cor[i] <- cor(pca$rotation[, i], as.numeric(as.factor(sex)), \\n            use = \"complete\")\\n    }\\n    top <- order(abs(pca.cor), decreasing = TRUE)[1]\\n    second <- order(abs(pca.cor), decreasing = TRUE)[2]\\n    print(paste(\"Top correlated principal components with sex:\", \\n        top, \",\", second))\\n    plot(pca$rotation[, top], pca$rotation[, second], pch = 16, \\n        col = c(\"magenta\", \"blue\")[as.factor(sex)], xlab = paste(\"PC\", \\n            top), ylab = paste(\"PC\", second))\\n    legend(\"topright\", levels(as.factor(sex)), pch = 16, col = c(\"magenta\", \\n        \"blue\"))\\n    predSex <- rep(NA, length(sex))\\n    options.sex <- levels(as.factor(sex))\\n    if (abs(pca.cor[top]) > 0.9) {\\n        print(\"Top PC has r > 0.9 with sex so good enough to confirm reported sexes\")\\n    }\\n    else {\\n        print(paste(\"Top PC has r =\", round(abs(pca.cor[top]), \\n            2), \"with sex so may not be good enough to confirm reported sexes\"))\\n    }\\n    if (sign(pca.cor[top]) == 1) {\\n        predSex[which(pca$rotation[, top] < 0)] <- options.sex[1]\\n        predSex[which(pca$rotation[, top] > 0)] <- options.sex[2]\\n    }\\n    else {\\n        predSex[which(pca$rotation[, top] < 0)] <- options.sex[2]\\n        predSex[which(pca$rotation[, top] > 0)] <- options.sex[1]\\n    }\\n    return(predSex)\\n}\\n\\n[[3]]$visible\\n[1] FALSE\\n\\n\\n[1] \"Phenotype information imported\"\\n[1] \"Finished reading and saving .idat files\"\\n[1] \"Top correlated principal components with sex: 3 , 1\"\\n[1] \"Top PC has r > 0.9 with sex so good enough to confirm reported sexes\"\\n[1] \"Top correlated principal components with sex: 3 , 1\"\\n0 samples having 5 % of sites with a detection p-value greater than 0.05 were removed \\nSamples removed:  \\n1103 sites were removed as beadcount <3 in 5 % of samples \\n1358 sites having 1 % of samples with a detection p-value greater than 0.05 were removed \\n'\n"
     ]
    }
   ],
   "source": [
    "#check what happend in the subprocess\n",
    "print(central_preprocessing.stderr)\n",
    "print(central_preprocessing.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to normalise the data, this step will be offered centrally and distributed/federated to be flexible to the researchers needs  \n",
    "Below a implementation of the normalisation algorithm behind the dasen function in the wateRmelon package is provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dasen normalisation is a form of quantile normalisation that is performed for the two probe types seperately. The normalised data (betas), per probe type, are calculated using the normalised methylated and unmethylated intensities of each probe type.  \n",
    "    betas (per probe) = quantile normalised methylated intensities / (quantile normalised methylated intensities + quantile normalised unmethylated intensities + 100)  \n",
    "The first step is to write the quantile normalisation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantile normalisation function\n",
    "def quantile_normalise(input_data):\n",
    "    \"\"\"\n",
    "    input_data = a dataframe that needs to be quantile normalised\n",
    "    returns a quantile normalised version of the input_data\n",
    "    \"\"\"\n",
    "    data_sorted = pd.DataFrame(np.sort(input_data.values, axis = 0), index = input_data.index, columns = input_data.columns) #sort the values of each column (sample) and keep the original row \n",
    "    # and column names\n",
    "    data_sorted_means = data_sorted.mean(axis = 1) # calulate the row means of the sorted data -> these means will be used to replace the raw values in the data\n",
    "    data_sorted_means.index = np.arange(1, len(data_sorted_means)+1) # this sets the index so it will correspond to the descending ranks that will be assigned to the original \n",
    "    # data in the dataframe. This way the row means, which are sorted loweste to highest, can be used to replace the raw data in the correct order\n",
    "    data_rank = input_data.rank(method = \"min\").stack().astype(int) # get the rank of the values for each sample in the raw dataset in integer format and change the dataframe so that\n",
    "    # the columns become the rows, with a multi-index indicating probe as the highest level and the samples for that probe as the second level\n",
    "    QN_data = data_rank.map(data_sorted_means).unstack() # map the row mean values onto the matching ranks obtained from the original dataframe and bring it back to a row = probe\n",
    "    # and column = sample format\n",
    "    return (QN_data)\n",
    "# works as it should\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the dasen function can be coded, first a couple of supporting functions need to be translated from r to python, these have been defined in the wateRmelon package as:  \n",
    "* dfs2\n",
    "* dfsfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in some data and create a test data object to write these functions\n",
    "test_methylated = pd.read_csv(\"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Federated_Differential_Methylation_Analysis\\\\Output\\\\QC_GSE66351_PythonShell\\\\Raw_methylated_intensities.csv\", index_col=0)\n",
    "test_methylated = test_methylated.iloc[0:21, 0:21]\n",
    "\n",
    "test_unmethylated = pd.read_csv(\"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Federated_Differential_Methylation_Analysis\\\\Output\\\\QC_GSE66351_PythonShell\\\\Raw_unmethylated_intensities.csv\", index_col=0)\n",
    "test_unmethylated = test_unmethylated.iloc[0:21, 0:21]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silke\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (2,4,11,14,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# attach the probe type information to the (test) data so it can be used by the normalisation functions\n",
    "annotation_data = pd.read_csv(\"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Data\\\\GSE66351_RAW\\\\GPL13534_HumanMethylation450_15017482_v.1.1.csv\", skiprows=7, low_memory=False)\n",
    "annotation_data.set_index(annotation_data[\"IlmnID\"], inplace=True)\n",
    "probe_type_data = annotation_data.loc[:, \"Infinium_Design_Type\"]\n",
    "test_probe_annotation = pd.merge(test_methylated, probe_type_data, how = \"inner\", left_index=True, right_index=True, indicator = True)\n",
    "test_probe_annotation = test_probe_annotation.loc[:,\"Infinium_Design_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save everything to test the next function in r\n",
    "test_methylated.to_csv(os.path.join(output_path, \"test_normalisation\\\\methylation.csv\"))\n",
    "test_unmethylated.to_csv(os.path.join(output_path, \"test_normalisation\\\\unmethylation.csv\"))\n",
    "test_probe_annotation.to_csv(os.path.join(output_path, \"test_normalisation\\\\probe_annotation.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs2_python_sklear(x, probe_type = test_probe_annotation):\n",
    "    from sklearn.neighbors import KernelDensity\n",
    "    #KD_one = KernelDensity(kernel = \"gaussian\", ).fit(x[probe_type == \"I\"])\n",
    "    #one = KD_one.score_samples(x[probe_type == \"I\"])\n",
    "    #KD_two = KernelDensity(kernel = \"gaussian\", ).fit(x[probe_type == \"II\"])\n",
    "    #two = KD_two.score_samples(x[probe_type == \"II\"])\n",
    "    #out = np.max(one) - np.max(two) #not quite sure if any of this is correct\n",
    "\n",
    "    # new code version that should work on one column at a time\n",
    "    x_copy = x.copy()\n",
    "    KD_one = KernelDensity(kernel = \"gaussian\", ).fit(np.array(x_copy[probe_type == \"I\"]).reshape(1,-1))\n",
    "    one = KD_one.score_samples(np.array(x_copy[probe_type == \"I\"]).reshape(1,-1))\n",
    "    KD_two = KernelDensity(kernel = \"gaussian\", ).fit(np.array(x_copy[probe_type == \"II\"]).reshape(1,-1))\n",
    "    two = KD_two.score_samples(np.array(x_copy[probe_type == \"II\"]).reshape(1,-1))\n",
    "    out = np.max(one) - np.max(two) #not quite sure if any of this is correct\n",
    "    return out\n",
    "\n",
    "# the code works - need to try a different desity estimator function because this returns the same value for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs2_python(x, probe_type):\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.distributions.mixture_rvs import mixture_rvs\n",
    "\n",
    "    # new code version that should work on one column at a time\n",
    "    x_copy = x.copy()\n",
    "    KD_one = sm.nonparametric.KDEUnivariate(x_copy[probe_type == \"I\"])\n",
    "    KD_one.fit(gridsize=5000)\n",
    "    one = int(KD_one.support[np.where(np.max(KD_one.density))])\n",
    "    KD_two = sm.nonparametric.KDEUnivariate(x_copy[probe_type == \"II\"])\n",
    "    KD_two.fit(gridsize=5000)\n",
    "    two = int(KD_two.support[np.where(np.max(KD_two.density))])\n",
    "    out = np.max(one) - np.max(two) #not quite sure if any of this is correct\n",
    "    return out\n",
    "\n",
    "#this one works more similar to the r original although the output is about a factor 10^-5 off compared to r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfsfit_python(x, probe_type):\n",
    "    import statsmodels.api as sm\n",
    "    import re\n",
    "    dis_diff = x.apply(dfs2_python, args = (probe_type,), axis=0) #create a dataframe/array of the values when dfs2 is applied to each column\n",
    "    \n",
    "    roco = []\n",
    "    for col_name in test_unmethylated.columns.values.tolist() :\n",
    "        found = re.search(\"(R0[1-9]C0[1-9])\", col_name).group(1)\n",
    "        roco.append(found) \n",
    "    \n",
    "    srow = []\n",
    "    scol = []\n",
    "    for ro in roco:\n",
    "        row = int(ro[2])\n",
    "        srow.append(row)\n",
    "        col = int(ro[5])\n",
    "        scol.append(col)\n",
    "    \n",
    "    fit_dist = sm.OLS.from_formula(\"dis_diff ~ scol + srow\", dis_diff).fit()\n",
    "    dis_diff = [fit_dist.fittedvalues]\n",
    "\n",
    "    tI_correction = np.tile(np.array(dis_diff), (3,1))\n",
    "    x[probe_type == \"I\"] = x[probe_type == \"I\"] - tI_correction\n",
    "    return x\n",
    "\n",
    "# this works too - although the output is about a factor 10^-5 off compared to r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dasen normalisation\n",
    "def dasen_normalisation(unmethylated, methylated, probe_type, base = 100):\n",
    "    \"\"\"\n",
    "    computes the dasen normalised beta values: quantile normalises the unmethylated and methylated intensities, per probe type,\n",
    "    and uses these normalised intensities to calculate the beta values\n",
    "\n",
    "    Input arguments:\n",
    "    unmethylated = dataframe of unmethylated intensities\n",
    "    methylated = dataframe of methylated intensities\n",
    "    probe_type = series indicating the type of each probe (Type I or Type II)\n",
    "\n",
    "    Returns: a dataframe of normalised beta values\n",
    "    \"\"\"\n",
    "    # fit the probability ditribution to the methylated and unmethylated probe intensities based on their probe type\n",
    "    unmethylated_fit = dfsfit_python(unmethylated, probe_type)\n",
    "    methylated_fit = dfsfit_python(methylated, probe_type)\n",
    "\n",
    "    # calculate the quantile normalised values for the methylated and unmethylated probe intensities based on the estimated distribution values\n",
    "    unmethylated[probe_type == \"I\"] = quantile_normalise(unmethylated_fit[probe_type == \"I\"])\n",
    "    unmethylated[probe_type == \"II\"] = quantile_normalise(unmethylated_fit[probe_type == \"II\"])\n",
    "\n",
    "    methylated[probe_type == \"I\"] = quantile_normalise(methylated_fit[probe_type == \"I\"])\n",
    "    methylated[probe_type == \"II\"] = quantile_normalise(methylated_fit[probe_type == \"II\"])\n",
    "\n",
    "    # calculate the new beta values based on the per probe normalised methylated and unmethylated probe intentisity values\n",
    "    betas = methylated/(methylated + unmethylated + base) \n",
    "    return betas\n",
    "# this also works as it should "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normalised_betas = dasen_normalisation(test_unmethylated, test_methylated, test_probe_annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, to move on to writing the EWAS code, I wrote a script around the normalisation with the dasen function and the cell type decomposition in r which will be run as a subprocess. The normalisation will be implemented in python in the final version but the cell type decomposition remains r based because there is limitted need to reimplement that in a federated fashion - THIS IS NOT WORKING, INLCUDED THE NORMALISATION AND CELL TYPE DECOMPOSITION INTO THE R-SCRIPT THAT IS RUN IN THE SUBPROCESS FOR NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalisation = \"dasen_normalisation.r\"\n",
    "normalisation_file = os.path.join(working_path, normalisation)\n",
    "data = os.path.join(output_path, \"preprocessed_MethyLumiSet.RData\") \n",
    "manifest_path = \"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Data\\\\GSE66351_RAW\\\\GPL13534_HumanMethylation450_15017482_v.1.1.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_normalisation = subprocess.run([\"C:\\\\Program Files\\\\R\\\\R-4.1.2\\\\bin\\\\Rscript.exe\", '--vanilla', normalisation_file, data, output_dir, manifest_path], capture_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_normalisation.stderr)\n",
    "print(r_normalisation.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R script containing the RefFreeEWAS cell type decomposition which will be run in a subprocess, output saved and added to the phenotype information that will be used in the EWAS furhter down in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the paths that go into the subprocess function\n",
    "file_path = os.path.join(working_path, \"RefFreeEWAS_local.r\")\n",
    "data_path = os.path.join(output_path, \"QC_GSE66351_PythonShell\", \"Preprocessed_Normalised_MethyLumiSet.RData\") #try again with different input data\n",
    "manifest_path = \"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Data\\\\GSE66351_RAW\\\\GPL13534_HumanMethylation450_15017482_v.1.1.csv\"\n",
    "pheno_path = os.path.join(output_path, \"QC_GSE66351_PythonShell\", \"post_norm_pheno_information.csv\")\n",
    "\n",
    "# RefFreeEWAS subprocess\n",
    "RefFreeEWAS = subprocess.run([\"C:\\\\Program Files\\\\R\\\\R-4.1.2\\\\bin\\\\Rscript.exe\", '--vanilla', file_path, data_path, pheno_path, manifest_path], capture_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefFreeEWAS.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dasen_normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EWAS code, based on the least squares linear algebra as used in the fortran code at the foundation of the lm() function in r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EWAS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pheno = pd.read_csv(\"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Federated_Differential_Methylation_Analysis\\\\Output\\\\QC_GSE66351_PythonShell\\\\post_norm_pheno_information.csv\", index_col= \"Sample_ID\")\n",
    "betas = pd.read_csv(\"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Federated_Differential_Methylation_Analysis\\Output\\\\QC_GSE66351_PythonShell\\\\Preprocessed_betas.csv\", index_col=0)\n",
    "x = pheno.loc[:,[\"Sample_diagnosis\", \"Sample_age\", \"Sample_sex\", \"Sample_sentrix_id\"]] # design matrix with the dependent/explainatory variables to be included in the model\n",
    "y = betas.iloc[0:21,:] # keeping it small now to test if everything works the way it should\n",
    "\n",
    "# The design matrix needs to consist of numeric representations of the covariates to be included in the model, i.e. binary diagnosis, binary sex, dummy sentrix etc.\n",
    "x[\"Sample_diagnosis\"] = (x[\"Sample_diagnosis\"] == \"diagnosis: AD\").astype(int) #create binary diagnosis with 1 = AD and 0 = CTR\n",
    "x[\"Sample_sex\"] = (x[\"Sample_sex\"] == \"Sex: F\").astype(int) #create binary sex with 1 = F and 0 = M\n",
    "# create dummy variables for the unique sentrix_ids present in the dataset - this code can be reused to create center number dummies in the federated version of the code\n",
    "unique_ids = x[\"Sample_sentrix_id\"].unique()\n",
    "for id in unique_ids:\n",
    "    x[id] = (x[\"Sample_sentrix_id\"] == id).astype(int)\n",
    "x.drop(columns=\"Sample_sentrix_id\", inplace = True)\n",
    "# turn the age variable into a continuous numerical variable without any leftover text\n",
    "x[\"Sample_age\"].replace(\"^[^:]*:\", \"\", regex=True, inplace=True)\n",
    "x[\"Sample_age\"] = pd.to_numeric(x[\"Sample_age\"])\n",
    "\n",
    "def EWAS_central(design_matrix, beta_values):\n",
    "    x_matrix = design_matrix.values\n",
    "    y_matrix = beta_values.values\n",
    "\n",
    "\n",
    "    n = y_matrix.shape[0] # select the number of rows of the beta matrix - #genes that the linear model will be calculated for\n",
    "    m = x.shape[1] #select the number of columns from the design matrix\n",
    "\n",
    "    import scipy.stats\n",
    "\n",
    "    coefficient = []\n",
    "    standard_error = []\n",
    "    t_stat = []\n",
    "    p_value = []\n",
    "    for i in range(0, n):\n",
    "        y_m = y_matrix[i, :]\n",
    "        x_t = x_matrix.T @ x_matrix\n",
    "        x_t_y = x_matrix.T @ y_m\n",
    "        x_t_inv = np.linalg.inv(x_t)\n",
    "        coef = x_t_inv @ x_t_y\n",
    "        coefficient.append(coef)\n",
    "        stan_er = np.diag(x_t_inv)\n",
    "        standard_error.append(stan_er)\n",
    "        t = coef/stan_er\n",
    "        t_stat.append(t)\n",
    "        df = y_matrix.shape[1]-2 #degrees of freedom is defined as number of observations - 2 \n",
    "        p = scipy.stats.t.sf(t, df)\n",
    "        p_value.append(p)\n",
    "\n",
    "#turn the results saved in lists into a dataframe for each covariate with the probe ids as index\n",
    "    result_coef = pd.DataFrame(coefficient, index=y.index, columns=x.columns)\n",
    "    result_staner = pd.DataFrame(standard_error, index = y.index, columns=x.columns)\n",
    "    result_tvalue = pd.DataFrame(t_stat, index=y.index, columns=x.columns)\n",
    "    result_pvalue = pd.DataFrame(p_value, index=y.index, columns=x.columns)\n",
    "\n",
    "#create a final results dataframe that contains the coefficient, standard error and p-value of the diagnosis covariate included in the linear regression\n",
    "    results_diagnosis = pd.DataFrame({\"Diagnosis_Coef\":result_coef[\"Sample_diagnosis\"], \"Diagnosis_StanErr\":result_staner[\"Sample_diagnosis\"], \"Diagnosis_Pvalue\":result_pvalue[\"Sample_diagnosis\"]}, index=y.index)\n",
    "    results_diagnosis.to_csv(os.path.join(output_path, \"results_diagnosis_regression_test_python.csv\"))\n",
    "    complete_results = pd.concat({\"Coefficient\":result_coef, \"StandardError\":result_staner, \"P-value\":result_pvalue}, axis = 1)\n",
    "    results_diagnosis.to_csv(os.path.join(output_path, \"complete_results_regression_test_python.csv\"))\n",
    "    return results_diagnosis, complete_results\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a .bed structured text file with the regression output to be used as input into the differentially methylated region analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with importing the probe information from the .bed file that is available through the encord project (?)\n",
    "bed_annotation = pd.read_csv(\"E:\\\\Msc Systems Biology\\\\MSB5000_Master_Thesis\\\\Practical work\\\\Data\\\\HAIB.A549.EtOH.Rep.3.bed\", sep=\"\\t\", header=None)\n",
    "# select the three necessary column, chr, start, stop from the annotation file and match these to the probes in the EWAS input betas based on probe ID\n",
    "bed_annotation = bed_annotation.iloc[:,0:4]\n",
    "bed_annotation.columns = [\"chr\", \"ChromStart\", \"ChromEnd\", \"Illumina_ID\"]\n",
    "# merge the regression output onto the .bed standard columns based on the probe ID\n",
    "results_bed = pd.merge(bed_annotation, results_diagnosis, left_on=\"Illumina_ID\", right_index=True, how=\"inner\") #using inner join since this preserves the order of the keys and\n",
    "# only keeps the entries that are present in both dataframes\n",
    "results_bed.set_index(results_bed[\"Illumina_ID\"], inplace=True)\n",
    "# write the dataframe as a tab separated .bed file\n",
    "results_bed.to_csv(os.path.join(output_path, \"results_diagnosis_regression_test.bed\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
